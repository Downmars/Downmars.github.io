<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Ollama on DLog</title>
    <link>http://localhost:1313/zh/tags/ollama/</link>
    <description>Recent content in Ollama on DLog</description>
    <generator>Hugo -- 0.143.1</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 09 Feb 2025 20:08:43 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/zh/tags/ollama/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2025_02_09 Ollama_deepseek_1</title>
      <link>http://localhost:1313/zh/posts/2025_02_09-ollama_deepseek_1/</link>
      <pubDate>Sun, 09 Feb 2025 20:08:43 +0800</pubDate>
      <guid>http://localhost:1313/zh/posts/2025_02_09-ollama_deepseek_1/</guid>
      <description>&lt;h2 id=&#34;ollama&#34;&gt;Ollama&lt;/h2&gt;
&lt;p&gt;&lt;blockquote class=&#34;quote&#34;&gt;&lt;p&gt;&amp;ldquo;Get up and running with large language models locally.&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;

想必大家一定从很多地方都看到过这个一直小羊驼&amp;ndash;&lt;a href=&#34;https://github.com/ollama/ollama&#34;
   
    
       target=&#34;_blank&#34; rel=&#34;noopener&#34; 
   
   class=&#34;custom-link&#34;&gt;  
   Ollama&lt;span class=&#34;external-link&#34;&gt;↗&lt;/span&gt;&lt;/a&gt;
，正如官方仓库所言，Ollama旨在简化大语言模型(LLMs)的本地部署和使用，我们能够通过这个这个工具来实现轻松下载、运行和管理各种开源的大语言模型。&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h2 id="ollama">Ollama</h2>
<p><blockquote class="quote"><p>&ldquo;Get up and running with large language models locally.&rdquo;</p></blockquote>

想必大家一定从很多地方都看到过这个一直小羊驼&ndash;<a href="https://github.com/ollama/ollama"
   
    
       target="_blank" rel="noopener" 
   
   class="custom-link">  
   Ollama<span class="external-link">↗</span></a>
，正如官方仓库所言，Ollama旨在简化大语言模型(LLMs)的本地部署和使用，我们能够通过这个这个工具来实现轻松下载、运行和管理各种开源的大语言模型。</p>
<ul>
<li>Ollama支持的模型仓库：<a href="https://ollama.com/library"
   
    
       target="_blank" rel="noopener" 
   
   class="custom-link">  
   https://ollama.com/library<span class="external-link">↗</span></a>
</li>
</ul>
<p>我在这里使用的是 deepseek-r1:14b，因为我的笔记本没有 GPU，但 Ollama 支持在没有 GPU 的情况下调用 CPU 来运行模型，所以也能够正常运行。</p>
<blockquote>
<p>注意：运行 7B 模型至少需要 8GB 内存，运行 14B 模型至少需要 16GB 内存，运行 33B 模型至少需要 32GB 内存。</p></blockquote>
<h2 id="deepseek">DeepSeek</h2>
<p><blockquote class="quote"><p>&ldquo;DeepSeek’s first-generation reasoning models, achieving performance comparable to OpenAI-o1 across math, code, and reasoning tasks.&rdquo;</p></blockquote>

<a href="https://www.deepseek.com/"
   
    
       target="_blank" rel="noopener" 
   
   class="custom-link">  
   DeepSeek<span class="external-link">↗</span></a>
<span class="sidenote-number"><small class="sidenote"><a href="https://github.com/deepseek-ai/DeepSeek-V3"
   
    
       target="_blank" rel="noopener" 
   
   class="custom-link">  
   DeepSeek-V3<span class="external-link">↗</span></a>
是其最新的开源模型项目，完整模型为671B，<a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf"
   
    
       target="_blank" rel="noopener" 
   
   class="custom-link">  
   论文链接<span class="external-link">↗</span></a></small></span>

（深度求索）是中国人工智能公司深度求索（DeepSeek Inc.）开发的一系列开源大语言模型（LLM），专注于高效推理和低成本部署。其模型以高性能和轻量化著称，适合学术研究、企业应用和个人开发者使用。</p>
<h2 id="安装ollama">安装Ollama</h2>
<p>














  
    
  

  
    
  









<p><details class="custom-collapse" open>
  <summary markdown="span">
    <span>zsh</span>
    <span class="line-count">1 lines</span>
  </summary>
  <div class="content">
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo pacman -S ollama  
</span></span></code></pre></div>
  </div>
</details></p>

官方推荐的方式为如下：<br>















  
    
  

  
    
  









<p><details class="custom-collapse" open>
  <summary markdown="span">
    <span>zsh</span>
    <span class="line-count">1 lines</span>
  </summary>
  <div class="content">
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -fsSL https://ollama.com/install.sh | sh  
</span></span></code></pre></div>
  </div>
</details></p>
</p>
<h2 id="下拉deepseek模型">下拉DeepSeek模型</h2>
<p>Ollama现在已经将deepseek模型接入官方库中，我们只需要通过以下命令拉取模型即可：<br>















  
    
  

  
    
  









<p><details class="custom-collapse" open>
  <summary markdown="span">
    <span>zsh</span>
    <span class="line-count">1 lines</span>
  </summary>
  <div class="content">
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama pull deepseek-r1:14b
</span></span></code></pre></div>
  </div>
</details></p>
</p>
<h2 id="通过ollama启动deepseek">通过Ollama启动DeepSeek</h2>
<p>经过上述部分，我们已经可以尝试本机运行DeepSeek了。通过以下命令启动Ollama服务：<br>















  
    
  

  
    
  









<p><details class="custom-collapse" open>
  <summary markdown="span">
    <span>zsh</span>
    <span class="line-count">1 lines</span>
  </summary>
  <div class="content">
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama server  
</span></span></code></pre></div>
  </div>
</details></p>

在启动Ollama服务过后，我们即可使用以下命令来尝试DeepSeek了：<br>















  
    
  

  
    
  









<p><details class="custom-collapse" open>
  <summary markdown="span">
    <span>zsh</span>
    <span class="line-count">1 lines</span>
  </summary>
  <div class="content">
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama run deepseek-r1:14b
</span></span></code></pre></div>
  </div>
</details></p>

运行示例如下：<br>















  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  









<p><details class="custom-collapse" >
  <summary markdown="span">
    <span>zsh</span>
    <span class="line-count">32 lines</span>
  </summary>
  <div class="content">
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>&gt;&gt;&gt; which is greater? 9.11 or 9.9
</span></span><span style="display:flex;"><span>&lt;think&gt;
</span></span><span style="display:flex;"><span>First, I observe that both numbers have the same whole number part, which is 9.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Next, I compare their decimal parts: 0.11 and 0.90.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Since 0.11 is less than 0.90, it follows that 9.11 is less than 9.9.
</span></span><span style="display:flex;"><span>&lt;/think&gt;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>To determine which number is greater between **9.11** and **9.9**, let&#39;s compare them step 
</span></span><span style="display:flex;"><span>by step.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">### Step 1: Understand the Numbers</span>
</span></span><span style="display:flex;"><span>- **9.11** can be written as <span style="color:#f1fa8c">\(</span><span style="color:#bd93f9">9</span> + <span style="color:#f1fa8c">\f</span>rac<span style="color:#ff79c6">{</span>11<span style="color:#ff79c6">}{</span>100<span style="color:#ff79c6">}</span><span style="color:#f1fa8c">\)</span>
</span></span><span style="display:flex;"><span>- **9.9** can be written as <span style="color:#f1fa8c">\(</span><span style="color:#bd93f9">9</span> + <span style="color:#f1fa8c">\f</span>rac<span style="color:#ff79c6">{</span>9<span style="color:#ff79c6">}{</span>10<span style="color:#ff79c6">}</span><span style="color:#f1fa8c">\)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">### Step 2: Compare the Decimal Parts</span>
</span></span><span style="display:flex;"><span>- The decimal part of **9.11** is **0.11**
</span></span><span style="display:flex;"><span>- The decimal part of **9.9** is **0.90**
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Now, compare **0.11** and **0.90**:
</span></span><span style="display:flex;"><span><span style="color:#f1fa8c">\[</span> 0.11 &lt; 0.90 <span style="color:#f1fa8c">\]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">### Step 3: Conclusion</span>
</span></span><span style="display:flex;"><span>Since the decimal part of **9.11** is less than that of **9.9**, it follows that:
</span></span><span style="display:flex;"><span><span style="color:#f1fa8c">\[</span> 9.11 &lt; 9.9 <span style="color:#f1fa8c">\]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Therefore, **9.9** is greater than **9.11**.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f1fa8c">\[</span>
</span></span><span style="display:flex;"><span><span style="color:#f1fa8c">\b</span>oxed<span style="color:#ff79c6">{</span>9.9<span style="color:#ff79c6">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f1fa8c">\]</span>
</span></span></code></pre></div>
  </div>
</details></p>
</p>
<h2 id="ollama-server-自启动">Ollama Server 自启动</h2>
<p>为了在开机时自启 Ollama Server，我们可以使用 systemd 来管理自动启动：<br>















  
    
  

  
    
  









<p><details class="custom-collapse" open>
  <summary markdown="span">
    <span>zsh</span>
    <span class="line-count">1 lines</span>
  </summary>
  <div class="content">
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo vim /etc/systemd/system/ollama-server.service
</span></span></code></pre></div>
  </div>
</details></p>

我们在其中填入以下内容：<br>















  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  









<p><details class="custom-collapse" open>
  <summary markdown="span">
    <span>/etc/systemd/system/ollama-server.service</span>
    <span class="line-count">12 lines</span>
  </summary>
  <div class="content">
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#ff79c6">[</span>Unit<span style="color:#ff79c6">]</span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">Description</span><span style="color:#ff79c6">=</span>Ollama Server
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">After</span><span style="color:#ff79c6">=</span>network.target
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">[</span>Service<span style="color:#ff79c6">]</span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">ExecStart</span><span style="color:#ff79c6">=</span>ollama serve
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">Restart</span><span style="color:#ff79c6">=</span>on-failure
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">RestartSec</span><span style="color:#ff79c6">=</span><span style="color:#bd93f9">5</span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">Environment</span><span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">HOME</span><span style="color:#ff79c6">=</span>/home/&lt;your home name&gt;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">[</span>Install<span style="color:#ff79c6">]</span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">WantedBy</span><span style="color:#ff79c6">=</span>multi-user.target
</span></span></code></pre></div>
  </div>
</details></p>

创建完服务文件后，通过以下指令来完成 systemd 配置：<br>















  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  









<p><details class="custom-collapse" open>
  <summary markdown="span">
    <span>zsh</span>
    <span class="line-count">11 lines</span>
  </summary>
  <div class="content">
    <div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># 重新加载 systemd 配置</span>
</span></span><span style="display:flex;"><span>sudo systemctl daemon-reload
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 下次开机后，启动开机自启</span>
</span></span><span style="display:flex;"><span>sudo systemctl <span style="color:#8be9fd;font-style:italic">enable</span> ollama-server.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 立刻启动服务</span>
</span></span><span style="display:flex;"><span>sudo systemctl start ollama-server.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 查看服务状态</span>
</span></span><span style="display:flex;"><span>sudo systemctl status ollama-server.service
</span></span></code></pre></div>
  </div>
</details></p>
</p>
<h2 id="通过open-webui-调用本地的deepseek-api">通过Open-webui 调用本地的DeepSeek api</h2>
<p>TODO</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
